{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad385cf0-067d-42ee-8ca2-a876e35143d0",
   "metadata": {},
   "source": [
    "# Personalized Restaurant Recommendation (Improved - No Data Leakage)\n",
    "\n",
    "**Task.** Given a user `u` and an unseen restaurant `i`, predict a personalized recommendation score $\\hat{r}_{u,i}$ (used for ranking). We evaluate rating prediction with **RMSE** and **MAE**.\n",
    "\n",
    "**Key Improvements over `baseline.ipynb`:**\n",
    "- **Fixed data leakage**: Removed use of current `review_text` which wouldn't be available at prediction time\n",
    "- **Proper user features**: Extract user preferences from `history_reviews` (past reviews)\n",
    "- **Sentiment analysis**: Added sentiment features from historical reviews\n",
    "\n",
    "**Dataset.** Google Restaurants — dataset of restaurants from Google Local (Google Maps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c6cb0-0874-4252-a687-df7fcc7bb16f",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58556a6b-a76e-479a-842e-cfe776dc30ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 87013, Val: 10860, Test: 11015\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "# Load data\n",
    "with open(\"filter_all_t.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "\n",
    "train_df = pd.DataFrame(data[\"train\"])\n",
    "val_df = pd.DataFrame(data.get(\"val\", []))\n",
    "test_df = pd.DataFrame(data.get(\"test\", []))\n",
    "\n",
    "# Remove pics column to save memory\n",
    "train_df = train_df.drop(columns=[\"pics\"], errors=\"ignore\")\n",
    "val_df = val_df.drop(columns=[\"pics\"], errors=\"ignore\")\n",
    "test_df = test_df.drop(columns=[\"pics\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65cbc020-173a-4adf-a584-d3cdae00f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean rating: 4.465\n",
      "Unique users in train: 29596\n",
      "Unique items in train: 27896\n"
     ]
    }
   ],
   "source": [
    "# Compute training statistics (used for all models)\n",
    "user_avg = train_df.groupby(\"user_id\")[\"rating\"].mean()\n",
    "item_avg = train_df.groupby(\"business_id\")[\"rating\"].mean()\n",
    "user_count = train_df.groupby(\"user_id\").size()\n",
    "item_count = train_df.groupby(\"business_id\").size()\n",
    "global_mean = train_df[\"rating\"].mean()\n",
    "\n",
    "print(f\"Global mean rating: {global_mean:.3f}\")\n",
    "print(f\"Unique users in train: {len(user_avg)}\")\n",
    "print(f\"Unique items in train: {len(item_avg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1625a-2fb6-4dc7-9591-28177e59c8f6",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "### Features:\n",
    "- `user_avg`, `item_avg`: Average ratings from **training data only**\n",
    "- `user_count`, `item_count`: Activity counts from **training data only**\n",
    "- `history_reviews`: User's **past reviews** (available at prediction time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2455a604-23c7-4f13-a909-c175ef7085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_history_features(history_reviews):\n",
    "    \"\"\"Extract features from user's historical reviews (NO LEAKAGE).\n",
    "    \n",
    "    Args:\n",
    "        history_reviews: List of [review_id, review_text] pairs\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of features extracted from historical reviews\n",
    "    \"\"\"\n",
    "    # Parse historical review texts\n",
    "    hist_texts = []\n",
    "    if history_reviews:\n",
    "        for h in history_reviews:\n",
    "            if len(h) >= 2 and h[1]:\n",
    "                hist_texts.append(h[1])\n",
    "    \n",
    "    if not hist_texts:\n",
    "        return {\n",
    "            'hist_count': 0,\n",
    "            'hist_avg_len': 0,\n",
    "            'hist_avg_polarity': 0,\n",
    "            'hist_avg_subjectivity': 0,\n",
    "            'hist_combined_text': \"\"\n",
    "        }\n",
    "    \n",
    "    # Text statistics\n",
    "    avg_len = np.mean([len(t) for t in hist_texts])\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    polarities = []\n",
    "    subjectivities = []\n",
    "    for text in hist_texts:\n",
    "        try:\n",
    "            blob = TextBlob(text)\n",
    "            polarities.append(blob.sentiment.polarity)\n",
    "            subjectivities.append(blob.sentiment.subjectivity)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    avg_polarity = np.mean(polarities) if polarities else 0\n",
    "    avg_subjectivity = np.mean(subjectivities) if subjectivities else 0\n",
    "    \n",
    "    return {\n",
    "        'hist_count': len(hist_texts),\n",
    "        'hist_avg_len': avg_len,\n",
    "        'hist_avg_polarity': avg_polarity,\n",
    "        'hist_avg_subjectivity': avg_subjectivity,\n",
    "        'hist_combined_text': \" \".join(hist_texts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3544bcf7-189b-43b8-8e77-32188d58628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting history features with sentiment analysis...\n",
      "Extracting history features with sentiment analysis...\n",
      "Extracting history features with sentiment analysis...\n"
     ]
    }
   ],
   "source": [
    "def add_features(df, user_avg, item_avg, user_count, item_count, global_mean):\n",
    "    \"\"\"Add legitimate features without data leakage.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # User/item statistics from training (legitimate)\n",
    "    df[\"user_avg\"] = df[\"user_id\"].map(user_avg).fillna(global_mean)\n",
    "    df[\"item_avg\"] = df[\"business_id\"].map(item_avg).fillna(global_mean)\n",
    "    df[\"user_count\"] = df[\"user_id\"].map(user_count).fillna(0)\n",
    "    df[\"item_count\"] = df[\"business_id\"].map(item_count).fillna(0)\n",
    "    \n",
    "    # Extract history features with sentiment\n",
    "    print(\"Extracting history features with sentiment analysis...\")\n",
    "    hist_features = df[\"history_reviews\"].apply(extract_history_features)\n",
    "    hist_df = pd.DataFrame(hist_features.tolist())\n",
    "    \n",
    "    df[\"hist_count\"] = hist_df[\"hist_count\"].values\n",
    "    df[\"hist_avg_len\"] = hist_df[\"hist_avg_len\"].values\n",
    "    df[\"hist_avg_polarity\"] = hist_df[\"hist_avg_polarity\"].values\n",
    "    df[\"hist_avg_subjectivity\"] = hist_df[\"hist_avg_subjectivity\"].values\n",
    "    df[\"hist_combined_text\"] = hist_df[\"hist_combined_text\"].values\n",
    "\n",
    "    df[\"history_reviews_num\"] = df['history_reviews'].apply(\n",
    "    lambda x: len(x) if isinstance(x, list) else 0\n",
    "    )\n",
    "    df[\"low_hist_flag\"] = (df[\"history_reviews_num\"] <= 3).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply features to all splits\n",
    "train_df = add_features(train_df, user_avg, item_avg, user_count, item_count, global_mean)\n",
    "val_df = add_features(val_df, user_avg, item_avg, user_count, item_count, global_mean)\n",
    "test_df = add_features(test_df, user_avg, item_avg, user_count, item_count, global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a7e96f-ce6c-4488-acaa-6a7aebdcc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features added:\n",
      "           user_avg      item_avg    hist_count  hist_avg_polarity  \\\n",
      "count  87013.000000  87013.000000  87013.000000       87013.000000   \n",
      "mean       4.465252      4.465252      3.399825           0.334748   \n",
      "std        0.576529      0.529461      4.476290           0.284386   \n",
      "min        1.000000      1.000000      0.000000          -1.000000   \n",
      "25%        4.100000      4.260870      1.000000           0.160000   \n",
      "50%        4.500000      4.555556      2.000000           0.325000   \n",
      "75%        5.000000      4.800000      4.000000           0.500000   \n",
      "max        5.000000      5.000000     45.000000           1.000000   \n",
      "\n",
      "       hist_avg_subjectivity  history_reviews_num  \n",
      "count           87013.000000         87013.000000  \n",
      "mean                0.574338             3.399837  \n",
      "std                 0.218916             4.476282  \n",
      "min                 0.000000             1.000000  \n",
      "25%                 0.475000             1.000000  \n",
      "50%                 0.596741             2.000000  \n",
      "75%                 0.707216             4.000000  \n",
      "max                 1.000000            45.000000  \n"
     ]
    }
   ],
   "source": [
    "# Verify features\n",
    "print(\"Features added:\")\n",
    "print(train_df[[\"user_avg\", \"item_avg\", \"hist_count\", \"hist_avg_polarity\", \"hist_avg_subjectivity\", \"history_reviews_num\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a3723-695c-4bc3-af24-7fa499568c19",
   "metadata": {},
   "source": [
    "## 3. Model 1: Linear Regression (Fixed - No TF-IDF on Current Review)\n",
    "\n",
    "**Original (LEAKING):** Used TF-IDF on `review_text` (current review)\n",
    "\n",
    "**Fixed:** Use only legitimate features:\n",
    "- User/item averages and counts\n",
    "- Historical review sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca606e8a-9bba-4551-a566-7bab375f228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 1: Ridge Regression (Fixed - No Leakage)\n",
      "==================================================\n",
      "Val  RMSE: 1.2164, MAE: 0.8226\n",
      "Test RMSE: 1.2473, MAE: 0.8320\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Legitimate features only (NO current review_text or review_len)\n",
    "feature_cols = [\n",
    "    \"user_avg\", \"item_avg\", \n",
    "    \"user_count\", \"item_count\",\n",
    "    \"hist_count\", \"hist_avg_len\",\n",
    "    \"hist_avg_polarity\", \"hist_avg_subjectivity\"\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols].values\n",
    "X_val = val_df[feature_cols].values\n",
    "X_test = test_df[feature_cols].values\n",
    "\n",
    "y_train = train_df[\"rating\"].values\n",
    "y_val = val_df[\"rating\"].values\n",
    "y_test = test_df[\"rating\"].values\n",
    "\n",
    "# Use Ridge regression for stability\n",
    "lr = Ridge(alpha=1.0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_val_lr = lr.predict(X_val)\n",
    "pred_test_lr = lr.predict(X_test)\n",
    "\n",
    "rmse_val_lr = np.sqrt(mean_squared_error(y_val, pred_val_lr))\n",
    "rmse_test_lr = np.sqrt(mean_squared_error(y_test, pred_test_lr))\n",
    "mae_val_lr = mean_absolute_error(y_val, pred_val_lr)\n",
    "mae_test_lr = mean_absolute_error(y_test, pred_test_lr)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Model 1: Ridge Regression (Fixed - No Leakage)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Val  RMSE: {rmse_val_lr:.4f}, MAE: {mae_val_lr:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test_lr:.4f}, MAE: {mae_test_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2f5b7a-3e8d-4b79-8970-6a88c8102580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Coefficients:\n",
      "  user_avg: 0.7572\n",
      "  item_avg: 0.6451\n",
      "  user_count: -0.1470\n",
      "  item_count: -0.0000\n",
      "  hist_count: 0.1459\n",
      "  hist_avg_len: 0.0001\n",
      "  hist_avg_polarity: -0.1562\n",
      "  hist_avg_subjectivity: 0.0252\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "for name, coef in zip(feature_cols, lr.coef_):\n",
    "    print(f\"  {name}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25c834-bf6f-4f00-aefa-64e2c6996796",
   "metadata": {},
   "source": [
    "## 4. Model 2: SVD + SBERT + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd33ad6b-0d27-4d50-adbb-fee8c751954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse shape = (29596, 27896)\n",
      "Sparsity = 0.9998946076254966\n",
      "SVD done\n",
      "Explained variance ratio: 0.029474984686464912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "user_map = {u: i for i, u in enumerate(train_df['user_id'].unique())}\n",
    "item_map = {b: i for i, b in enumerate(train_df['business_id'].unique())}\n",
    "\n",
    "rows = train_df['user_id'].map(user_map).values\n",
    "cols = train_df['business_id'].map(item_map).values\n",
    "data = train_df['rating'].values\n",
    "\n",
    "# Sparse matrix\n",
    "R_sparse = csr_matrix((data, (rows, cols)),\n",
    "                      shape=(len(user_map), len(item_map)))\n",
    "\n",
    "print(\"Sparse shape =\", R_sparse.shape)\n",
    "print(\"Sparsity =\", 1 - R_sparse.count_nonzero() / (R_sparse.shape[0] * R_sparse.shape[1]))\n",
    "\n",
    "# Fit SVD\n",
    "n_factors = 20\n",
    "svd = TruncatedSVD(n_components=n_factors, random_state=42)\n",
    "U = svd.fit_transform(R_sparse)\n",
    "V = svd.components_.T\n",
    "\n",
    "print(\"SVD done\")\n",
    "print(\"Explained variance ratio:\", svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0467a907-4f1b-45e3-a53a-eb6ff004d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model 2: SVD (Already Leak-Free)\n",
      "==================================================\n",
      "Val  RMSE: 0.9448, MAE: 0.6793\n",
      "Test RMSE: 0.9123, MAE: 0.6630\n"
     ]
    }
   ],
   "source": [
    "user_means = train_df.groupby('user_id')['rating'].mean()\n",
    "item_means = train_df.groupby('business_id')['rating'].mean()\n",
    "global_mean = train_df['rating'].mean()\n",
    "\n",
    "def svd_predict(df):\n",
    "    \"\"\"Safe SVD prediction using dot products (no large R_hat matrix).\"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        uid, bid = row['user_id'], row['business_id']\n",
    "        \n",
    "        has_user = uid in user_map\n",
    "        has_item = bid in item_map\n",
    "        \n",
    "        if has_user and has_item:\n",
    "            u_idx = user_map[uid]\n",
    "            i_idx = item_map[bid]\n",
    "            pred = np.dot(U[u_idx], V[i_idx])\n",
    "        \n",
    "        elif has_user:\n",
    "            pred = user_means.get(uid, global_mean)\n",
    "        \n",
    "        elif has_item:\n",
    "            pred = item_means.get(bid, global_mean)\n",
    "        \n",
    "        else:\n",
    "            pred = global_mean\n",
    "        \n",
    "        preds.append(pred)\n",
    "    \n",
    "    return np.array(preds)\n",
    "\n",
    "pred_val_svd = svd_predict(val_df)\n",
    "pred_test_svd = svd_predict(test_df)\n",
    "\n",
    "rmse_val_svd = np.sqrt(mean_squared_error(y_val, pred_val_svd))\n",
    "rmse_test_svd = np.sqrt(mean_squared_error(y_test, pred_test_svd))\n",
    "mae_val_svd = mean_absolute_error(y_val, pred_val_svd)\n",
    "mae_test_svd = mean_absolute_error(y_test, pred_test_svd)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Model 2: SVD (Already Leak-Free)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Val  RMSE: {rmse_val_svd:.4f}, MAE: {mae_val_svd:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test_svd:.4f}, MAE: {mae_test_svd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33342ddf-e3ee-4240-ab3b-5293891a1138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mio\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SentenceTransformer with embedding dim: 128\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load model\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dim = 128\n",
    "\n",
    "print(f\"Loaded SentenceTransformer with embedding dim: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25c9960-5b1b-4de7-8181-afd833c7884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_embedding_from_history(history_reviews, model):\n",
    "    \"\"\"Build user embedding from history_reviews ONLY (no leakage).\"\"\"\n",
    "    if not history_reviews:\n",
    "        return None  # let fallback handle it\n",
    "    hist_texts = []\n",
    "    if history_reviews:\n",
    "        for h in history_reviews:\n",
    "            if len(h) >= 2 and h[1]:\n",
    "                hist_texts.append(h[1])\n",
    "    \n",
    "    if not hist_texts:\n",
    "        return None\n",
    "    \n",
    "    lengths = np.array([len(t) for t in hist_texts])\n",
    "    weights = lengths / lengths.sum()\n",
    "\n",
    "    embs = model.encode(hist_texts, convert_to_tensor=True)\n",
    "    user_emb = (embs * torch.tensor(weights, device=embs.device).unsqueeze(1)).sum(dim=0)\n",
    "    return user_emb.cpu().numpy()\n",
    "\n",
    "\n",
    "def build_item_embeddings(train_df, model, batch_size=16):\n",
    "    \"\"\"\n",
    "    Build item embeddings for each business_id.\n",
    "    Efficient, memory-safe, avoids SBERT bottlenecks.\n",
    "    \"\"\"\n",
    "    item_emb_dict = {}\n",
    "\n",
    "    # Pre-group but do NOT materialize whole groups at once\n",
    "    grouped = train_df.groupby('business_id')['review_text']\n",
    "\n",
    "    for bid, texts in tqdm(grouped, desc=\"Building item embeddings\"):\n",
    "        texts = [t for t in texts.dropna().tolist() if isinstance(t, str)]\n",
    "\n",
    "        if len(texts) == 0:\n",
    "            continue\n",
    "\n",
    "        all_embs = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            batch_embs = model.encode(\n",
    "                batch,\n",
    "                show_progress_bar=False,\n",
    "                convert_to_tensor=False\n",
    "            )\n",
    "            all_embs.append(batch_embs)\n",
    "\n",
    "        all_embs = np.vstack(all_embs)\n",
    "        avg_emb = all_embs.mean(axis=0)\n",
    "        item_emb_dict[bid] = avg_emb.tolist()\n",
    "\n",
    "    return item_emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0674e271-8ad6-41ae-b4e5-7305ddcc50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building item embeddings from training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building item embeddings: 100%|██████████| 27896/27896 [03:12<00:00, 144.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built embeddings for 27896 items\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Build item embeddings from training data\n",
    "print(\"Building item embeddings from training data...\")\n",
    "item_emb_dict = build_item_embeddings(train_df, st_model)\n",
    "print(f\"Built embeddings for {len(item_emb_dict)} items\")\n",
    "\n",
    "# Compute global embedding for cold-start fallback\n",
    "global_item_emb = np.mean(list(item_emb_dict.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696d594e-a456-4ec8-a186-14bb3bfe0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_vector(x, dim):\n",
    "    \"\"\"Ensure x is a numpy vector of fixed dimension.\"\"\"\n",
    "    x = np.array(x, dtype=float).flatten()\n",
    "    if len(x) != dim:\n",
    "        return np.zeros(dim)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_hybrid_features_for_model(\n",
    "    df,\n",
    "    st_model,\n",
    "    item_emb_dict,\n",
    "    global_item_emb,\n",
    "    svd_user_emb,\n",
    "    svd_item_emb,\n",
    "    embedding_dim=384,\n",
    "    svd_dim=50\n",
    "):\n",
    "    X_list = []\n",
    "\n",
    "    global_user_emb = np.zeros(embedding_dim)\n",
    "    zero_svd_user = np.zeros(svd_dim)\n",
    "    zero_svd_item = np.zeros(svd_dim)\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Hybrid Features\"):\n",
    "\n",
    "        # ---------- 1. RAW user embedding ----------\n",
    "        u_emb = build_user_embedding_from_history(row[\"history_reviews\"], st_model)\n",
    "        u_emb = safe_vector(u_emb if u_emb is not None else global_user_emb, embedding_dim)\n",
    "\n",
    "        # ---------- 2. RAW item embedding ----------\n",
    "        i_emb = item_emb_dict.get(row[\"business_id\"], global_item_emb)\n",
    "        i_emb = safe_vector(i_emb, embedding_dim)\n",
    "\n",
    "        # ---------- 3. SVD embeddings ----------\n",
    "        u_svd = safe_vector(svd_user_emb.get(row['user_id'], zero_svd_user), svd_dim)\n",
    "        i_svd = safe_vector(svd_item_emb.get(row['business_id'], zero_svd_item), svd_dim)\n",
    "\n",
    "        # ---------- 4. numeric features ----------\n",
    "        history_num = float(row.get(\"history_reviews_num\", 0) or 0)\n",
    "        low_hist_flag = 1 if history_num <= 3 else 0\n",
    "        hist_pol = float(row.get(\"hist_avg_polarity\", 0) or 0)\n",
    "        hist_subj = float(row.get(\"hist_avg_subjectivity\", 0) or 0)\n",
    "        user_avg = float(row.get(\"user_avg\", 0) or 0)\n",
    "        item_avg = float(row.get(\"item_avg\", 0) or 0)\n",
    "\n",
    "        # ---------- 5. concat ----------\n",
    "        feat = np.concatenate([\n",
    "            u_emb,\n",
    "            i_emb,\n",
    "            u_svd,\n",
    "            i_svd,\n",
    "            [user_avg, item_avg, hist_pol, hist_subj, history_num, low_hist_flag]\n",
    "        ])\n",
    "        X_list.append(feat)\n",
    "\n",
    "    return np.vstack(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7352eb16-6b8c-485c-91e0-9f00657ecf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_user_emb = {uid: U[user_map[uid]] for uid in user_map}\n",
    "svd_item_emb = {bid: V[item_map[bid]] for bid in item_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45c66e2-7cc4-439b-9ef6-26101a638fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Hybrid Features: 100%|██████████| 87013/87013 [10:29<00:00, 138.26it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = build_hybrid_features_for_model(\n",
    "    train_df,\n",
    "    st_model,\n",
    "    item_emb_dict,\n",
    "    global_item_emb,\n",
    "    svd_user_emb,\n",
    "    svd_item_emb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b0d9d5a-5082-4e5e-a1e9-85aaa26af592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Hybrid Features: 100%|██████████| 10860/10860 [01:53<00:00, 95.78it/s] \n"
     ]
    }
   ],
   "source": [
    "X_val = build_hybrid_features_for_model(\n",
    "    val_df, st_model, item_emb_dict, global_item_emb,\n",
    "    svd_user_emb, svd_item_emb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc145390-c694-433b-8556-f3a9a614e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Hybrid Features: 100%|██████████| 11015/11015 [01:27<00:00, 125.97it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = build_hybrid_features_for_model(\n",
    "    test_df, st_model, item_emb_dict, global_item_emb,\n",
    "    svd_user_emb, svd_item_emb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c41b9515-5873-40ec-ab0f-4033129a0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "train_ds = RatingDataset(X_train_scaled, y_train)\n",
    "val_ds = RatingDataset(X_val_scaled, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f173cff-da64-44bd-a97d-e1ab38c844ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | train MSE=0.9641 | val MSE=1.1342 | val RMSE=1.0650 | val MAE=0.8389\n",
      "Epoch 01 | train MSE=0.5397 | val MSE=1.0040 | val RMSE=1.0020 | val MAE=0.8041\n",
      "Epoch 02 | train MSE=0.4472 | val MSE=0.9625 | val RMSE=0.9811 | val MAE=0.8089\n",
      "Epoch 03 | train MSE=0.3992 | val MSE=0.8976 | val RMSE=0.9474 | val MAE=0.7550\n",
      "Epoch 04 | train MSE=0.3602 | val MSE=0.8057 | val RMSE=0.8976 | val MAE=0.6995\n",
      "Epoch 05 | train MSE=0.3361 | val MSE=0.8218 | val RMSE=0.9065 | val MAE=0.6880\n",
      "Epoch 06 | train MSE=0.3156 | val MSE=0.8352 | val RMSE=0.9139 | val MAE=0.6696\n",
      "Epoch 07 | train MSE=0.3055 | val MSE=0.8126 | val RMSE=0.9014 | val MAE=0.6965\n",
      "Epoch 08 | train MSE=0.2897 | val MSE=0.8029 | val RMSE=0.8961 | val MAE=0.6930\n",
      "Epoch 09 | train MSE=0.2766 | val MSE=0.8336 | val RMSE=0.9130 | val MAE=0.6881\n",
      "Epoch 10 | train MSE=0.2688 | val MSE=0.8434 | val RMSE=0.9184 | val MAE=0.6699\n",
      "Epoch 11 | train MSE=0.2595 | val MSE=0.8117 | val RMSE=0.9010 | val MAE=0.6998\n",
      "Epoch 12 | train MSE=0.2524 | val MSE=0.8160 | val RMSE=0.9034 | val MAE=0.6946\n",
      "Epoch 13 | train MSE=0.2406 | val MSE=0.8152 | val RMSE=0.9029 | val MAE=0.7003\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = MLP(input_dim=X_train_scaled.shape[1])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val = float('inf')\n",
    "best_state = None\n",
    "patience = 5\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    # ---- train ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        pred = model(Xb)\n",
    "        loss = criterion(pred, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * len(Xb)\n",
    "    train_loss /= len(train_ds)\n",
    "\n",
    "    # ---- val ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_trues = []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            pred = model(Xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            val_loss += loss.item() * len(Xb)\n",
    "\n",
    "            val_preds.append(pred.numpy())\n",
    "            val_trues.append(yb.numpy())\n",
    "\n",
    "    val_loss /= len(val_ds)\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_trues = np.concatenate(val_trues)\n",
    "    val_rmse = np.sqrt(((val_preds - val_trues) ** 2).mean())\n",
    "    val_mae  = np.abs(val_preds - val_trues).mean()\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train MSE={train_loss:.4f} | \"\n",
    "          f\"val MSE={val_loss:.4f} | val RMSE={val_rmse:.4f} | val MAE={val_mae:.4f}\")\n",
    "\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac91682-7f52-4b5e-a77a-0e60fa7e12ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  0.6770\n",
      "Test RMSE: 0.8655\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_test = model(X_test_t).numpy()\n",
    "mae_test = mean_absolute_error(y_test, pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "\n",
    "print(f\"Test MAE:  {mae_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf282e8-176e-41a5-bfee-14e97f2d5644",
   "metadata": {},
   "source": [
    "## 5. Model 3: Word2Vec + CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c612eb50-ca70-47c3-8e5a-ba6c91d912fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train size: 87013, Val size: 10860, Test size: 11015\n",
      "Preparing Word2Vec training corpus from TRAIN history reviews...\n",
      "Training Word2Vec on 87013 history review sequences...\n",
      "Vocab size (with PAD/UNK): 16186\n",
      "Num train users: 29596, num train items: 27896\n",
      "NUM_USERS (with UNK): 29597, NUM_ITEMS (with UNK): 27897\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load data\n",
    "# ---------------------------\n",
    "print(\"Loading data...\")\n",
    "with open(\"filter_all_t.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(data[\"train\"])\n",
    "val_df   = pd.DataFrame(data.get(\"val\", []))\n",
    "test_df  = pd.DataFrame(data.get(\"test\", []))\n",
    "\n",
    "# Keep only the columns we need\n",
    "train_df = train_df[['user_id', 'business_id', 'rating', 'history_reviews']]\n",
    "val_df   = val_df[['user_id', 'business_id', 'rating', 'history_reviews']]\n",
    "test_df  = test_df[['user_id', 'business_id', 'rating', 'history_reviews']]\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Preprocessing helpers\n",
    "# ---------------------------\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Fast preprocessing: lowercase, remove non-alpha, split.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def extract_history_text(history_reviews, max_reviews=5):\n",
    "    \"\"\"Extract text from history reviews (could be list, array, or string).\"\"\"\n",
    "    # Handle None or NaN\n",
    "    if history_reviews is None or (isinstance(history_reviews, float) and pd.isna(history_reviews)):\n",
    "        return ''\n",
    "    \n",
    "    # Handle empty string\n",
    "    if isinstance(history_reviews, str) and history_reviews.strip() == '':\n",
    "        return ''\n",
    "    \n",
    "    # Handle list or array\n",
    "    if isinstance(history_reviews, (list, np.ndarray)):\n",
    "        if len(history_reviews) == 0:\n",
    "            return ''\n",
    "        # Take the most recent reviews\n",
    "        recent = history_reviews[-max_reviews:] if len(history_reviews) > max_reviews else history_reviews\n",
    "        return ' '.join([str(r) for r in recent if r and str(r).strip()])\n",
    "    \n",
    "    # Handle string or other types\n",
    "    return str(history_reviews)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Train Word2Vec on TRAIN history reviews only\n",
    "# ---------------------------\n",
    "print(\"Preparing Word2Vec training corpus from TRAIN history reviews...\")\n",
    "train_history_texts = []\n",
    "for history in train_df['history_reviews']:\n",
    "    history_text = extract_history_text(history)\n",
    "    if history_text:\n",
    "        train_history_texts.append(history_text)\n",
    "\n",
    "sentences = [preprocess_text(t) for t in train_history_texts]\n",
    "sentences = [s for s in sentences if len(s) > 3]  # remove very short sequences\n",
    "\n",
    "print(f\"Training Word2Vec on {len(sentences)} history review sequences...\")\n",
    "word2vec = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=3,\n",
    "    min_count=5,\n",
    "    workers=1,  # Single worker for reproducibility\n",
    "    sg=1,\n",
    "    epochs=8,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Build word->idx mapping (PAD=0, UNK=1)\n",
    "word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for i, word in enumerate(word2vec.wv.key_to_index.keys(), start=2):\n",
    "    word_to_idx[word] = i\n",
    "vocab_size = len(word_to_idx)\n",
    "print(f\"Vocab size (with PAD/UNK): {vocab_size}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Global user/item mappings from TRAIN\n",
    "# ---------------------------\n",
    "train_users = train_df['user_id'].unique()\n",
    "train_items = train_df['business_id'].unique()\n",
    "\n",
    "user_to_idx_global = {uid: i for i, uid in enumerate(train_users)}\n",
    "item_to_idx_global = {bid: i for i, bid in enumerate(train_items)}\n",
    "\n",
    "UNK_USER = len(user_to_idx_global)    # index for unseen users\n",
    "UNK_ITEM = len(item_to_idx_global)    # index for unseen items\n",
    "\n",
    "# Sizes for embeddings (add 1 for UNK)\n",
    "NUM_USERS = len(user_to_idx_global) + 1\n",
    "NUM_ITEMS = len(item_to_idx_global) + 1\n",
    "\n",
    "print(f\"Num train users: {len(user_to_idx_global)}, num train items: {len(item_to_idx_global)}\")\n",
    "print(f\"NUM_USERS (with UNK): {NUM_USERS}, NUM_ITEMS (with UNK): {NUM_ITEMS}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Dataset using HISTORY reviews\n",
    "# ---------------------------\n",
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx, max_length=200, max_history_reviews=5):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_length = max_length\n",
    "        self.max_history_reviews = max_history_reviews\n",
    "\n",
    "        # Use global mappings\n",
    "        self.user_to_idx = user_to_idx_global\n",
    "        self.item_to_idx = item_to_idx_global\n",
    "\n",
    "        # Precompute token indices from HISTORY reviews\n",
    "        self.sequences = []\n",
    "        self.history_lengths = []\n",
    "        \n",
    "        for history in self.df['history_reviews']:\n",
    "            history_text = extract_history_text(history, max_reviews=max_history_reviews)\n",
    "            tokens = preprocess_text(history_text)\n",
    "            self.history_lengths.append(min(len(tokens), max_length))\n",
    "\n",
    "            tokens = tokens[:max_length]\n",
    "            indices = [word_to_idx.get(tok, 1) for tok in tokens]  # UNK=1\n",
    "            if len(indices) < max_length:\n",
    "                indices = indices + [0] * (max_length - len(indices))\n",
    "            self.sequences.append(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        u = self.user_to_idx.get(row['user_id'], UNK_USER)\n",
    "        i = self.item_to_idx.get(row['business_id'], UNK_ITEM)\n",
    "\n",
    "        return {\n",
    "            'user_idx': torch.tensor(u, dtype=torch.long),\n",
    "            'item_idx': torch.tensor(i, dtype=torch.long),\n",
    "            'history_seq': torch.tensor(self.sequences[idx], dtype=torch.long),\n",
    "            'history_length': torch.tensor(self.history_lengths[idx], dtype=torch.float32),\n",
    "            'rating': torch.tensor(row['rating'], dtype=torch.float32)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3ab062f-607d-4c1e-9bc6-57bf3866dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6) Model: Predict based on user history + user/item embeddings\n",
    "# ---------------------------\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HistoryBasedRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_items, vocab_size, embedding_dim=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        # User & item embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, 32)\n",
    "        self.item_emb = nn.Embedding(num_items, 32)\n",
    "        \n",
    "        # Word embeddings for history reviews\n",
    "        self.word_emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self._init_word_embeddings(word2vec, word_to_idx)\n",
    "        \n",
    "        # 1D CNN to encode user's history\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout_text = nn.Dropout(0.2)\n",
    "        \n",
    "        # Predictor: combines user, item, and user history\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(32 + 32 + 128 + 1, 128),  # user + item + history + length\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def _init_word_embeddings(self, word2vec, word_to_idx):\n",
    "        \"\"\"Initialize word embeddings with Word2Vec.\"\"\"\n",
    "        embedding_matrix = np.zeros((len(word_to_idx), 100))\n",
    "        for word, idx in word_to_idx.items():\n",
    "            if word in word2vec.wv:\n",
    "                embedding_matrix[idx] = word2vec.wv[word]\n",
    "            elif word == '<UNK>':\n",
    "                embedding_matrix[idx] = np.random.normal(scale=0.1, size=(100,))\n",
    "        self.word_emb.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        print(f\"Initialized {np.sum(np.any(embedding_matrix != 0, axis=1))} words from Word2Vec\")\n",
    "    \n",
    "    def forward(self, user_idx, item_idx, history_seq, history_length):\n",
    "        # User & item embeddings\n",
    "        user_emb = self.user_emb(user_idx)  # [batch, 32]\n",
    "        item_emb = self.item_emb(item_idx)  # [batch, 32]\n",
    "        \n",
    "        # History text embeddings (CNN)\n",
    "        word_embs = self.word_emb(history_seq)      # [batch, seq_len, embed_dim]\n",
    "        x = word_embs.transpose(1, 2)               # [batch, embed_dim, seq_len]\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(-1)                # [batch, 128]\n",
    "        x = self.dropout_text(x)\n",
    "        \n",
    "        # Normalize history length\n",
    "        history_length_norm = (history_length / 200.0).unsqueeze(1)  # [batch, 1]\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([user_emb, item_emb, x, history_length_norm], dim=1)\n",
    "        rating = self.predictor(combined).squeeze(-1)\n",
    "        return rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1cdf501-5f51-4aaa-8fbb-51a1a740fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7) Training & evaluation utilities\n",
    "# ---------------------------\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            user_idx = batch['user_idx'].to(device)\n",
    "            item_idx = batch['item_idx'].to(device)\n",
    "            history_seq = batch['history_seq'].to(device)\n",
    "            history_length = batch['history_length'].to(device)\n",
    "            rating = batch['rating'].to(device)\n",
    "\n",
    "            out = model(user_idx, item_idx, history_seq, history_length)\n",
    "            preds.extend(out.cpu().numpy())\n",
    "            targets.extend(rating.cpu().numpy())\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    return rmse, mae, np.array(preds), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db70e9e3-ccd3-41ed-b7b1-78274515af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 8) Training loop\n",
    "# ---------------------------\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def train_recommender(num_epochs=10, batch_size=128, lr=1e-3, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    train_dataset = RecommendationDataset(train_df, word_to_idx, max_length=200)\n",
    "    val_dataset   = RecommendationDataset(val_df, word_to_idx, max_length=200)\n",
    "    test_dataset  = RecommendationDataset(test_df, word_to_idx, max_length=200)\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = HistoryBasedRecommender(\n",
    "        num_users=NUM_USERS, \n",
    "        num_items=NUM_ITEMS, \n",
    "        vocab_size=vocab_size\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\"Model params:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 3\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds, train_targets = [], []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            user_idx = batch['user_idx'].to(device)\n",
    "            item_idx = batch['item_idx'].to(device)\n",
    "            history_seq = batch['history_seq'].to(device)\n",
    "            history_length = batch['history_length'].to(device)\n",
    "            rating = batch['rating'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(user_idx, item_idx, history_seq, history_length)\n",
    "            loss = criterion(out, rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_preds.extend(out.detach().cpu().numpy())\n",
    "            train_targets.extend(rating.cpu().numpy())\n",
    "\n",
    "        train_rmse = np.sqrt(mean_squared_error(train_targets, train_preds))\n",
    "        train_mae  = mean_absolute_error(train_targets, train_preds)\n",
    "\n",
    "        val_rmse, val_mae, _, _ = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}:\")\n",
    "        print(f\"  Train RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}\")\n",
    "        print(f\"  Val   RMSE: {val_rmse:.4f}, MAE: {val_mae:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(\" New best model\")\n",
    "            patience_counter = patience\n",
    "        else:\n",
    "            patience_counter -= 1\n",
    "            print(f\"  Patience left: {patience_counter}\")\n",
    "            if patience_counter <= 0:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Test with best model\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Evaluating best model on test set...\")\n",
    "    model.load_state_dict(best_model_state)\n",
    "    test_rmse, test_mae, test_preds, test_targets = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    return test_rmse, test_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f73889e-6395-4f58-b9cc-11a3a7f01fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING HISTORY-BASED RECOMMENDER\n",
      "==================================================\n",
      "Device: cuda\n",
      "Initialized 16185 words from Word2Vec\n",
      "Model params: 3530089\n",
      "\n",
      "Epoch 1/10:\n",
      "  Train RMSE: 1.1121, MAE: 0.8126\n",
      "  Val   RMSE: 0.9160, MAE: 0.7693\n",
      " New best model\n",
      "\n",
      "Epoch 2/10:\n",
      "  Train RMSE: 0.9014, MAE: 0.6913\n",
      "  Val   RMSE: 0.8593, MAE: 0.7040\n",
      " New best model\n",
      "\n",
      "Epoch 3/10:\n",
      "  Train RMSE: 0.8782, MAE: 0.6713\n",
      "  Val   RMSE: 0.8922, MAE: 0.7433\n",
      "  Patience left: 2\n",
      "\n",
      "Epoch 4/10:\n",
      "  Train RMSE: 0.8524, MAE: 0.6495\n",
      "  Val   RMSE: 1.0096, MAE: 0.8730\n",
      "  Patience left: 1\n",
      "\n",
      "Epoch 5/10:\n",
      "  Train RMSE: 0.8184, MAE: 0.6200\n",
      "  Val   RMSE: 0.9382, MAE: 0.7932\n",
      "  Patience left: 0\n",
      "Early stopping triggered.\n",
      "\n",
      "==================================================\n",
      "Evaluating best model on test set...\n",
      "\n",
      "==================================================\n",
      "FINAL TEST RESULTS\n",
      "==================================================\n",
      "Test RMSE: 0.9281\n",
      "Test MAE:  0.7841\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 9) Main\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING HISTORY-BASED RECOMMENDER\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_rmse, test_mae = train_recommender(num_epochs=10, batch_size=128, lr=1e-3)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL TEST RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Test MAE:  {test_mae:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
